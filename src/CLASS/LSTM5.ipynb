{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whs1111/bert-version/blob/master/src/CLASS/LSTM5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb0U7ctSDcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23552bf9-304f-41a5-9c96-b5def8f6cc52"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8U2HuDtZix"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orTnaAutSYb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373ab4db-4ff1-436e-eb5f-5ae2876dcfa5"
      },
      "source": [
        "cd gdrive/My Drive/Colab_Notebooks/code\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNs9soyfIdAY"
      },
      "source": [
        "#@title\n",
        "!git clone https://github.com/NVIDIA/apex.git\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "%cd ..\n",
        "\n",
        "import torch\n",
        "import apex\n",
        "from fastai.text import *\n",
        "import datetime\n",
        "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "LOG_PATH=Path('logs/')  \n",
        "MODEL_PATH=Path('models/') \n",
        "\n",
        "if not LOG_PATH.exists():\n",
        "  LOG_PATH.mkdir()\n",
        "import logging\n",
        "\n",
        "args = {\n",
        "    \"run_text\": \"my_test\",\n",
        "    \"max_seq_length\": 30,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 16,\n",
        "    \"learning_rate\": 6e-5,\n",
        "    \"num_train_epochs\": 12.0,\n",
        "    \"warmup_proportion\": 0.002,\n",
        "    \"local_rank\": -1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"fp16\": True,\n",
        "    \"loss_scale\": 128\n",
        "}\n",
        "\n",
        "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(logfile),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ])\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    multi_gpu = True\n",
        "else:\n",
        "    multi_gpu = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdR4a-QwQIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa004313-d950-44ec-8680-ff90654804b9"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/b7/e896bcb1b68ce11eb54aabb76f3416fc52e66fddded97cf6d68ad78494f4/boto3-1.16.44-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.19.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.44\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/ca/0d28c0654269b2bd74c504af1e7ced767dbf5028a8478960f51868fa35bd/botocore-1.19.44-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 22.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.44->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.44->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.19.44 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.44 botocore-1.19.44 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UPCpIKpC7Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43680a10-1fd3-4661-a964-00be1de3957d"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxTo7cgvvy_C"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertModel\n",
        "import torch\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "a = \"i am a dog\"\n",
        "a_tokens = bert_tokenizer.tokenize(a)\n",
        "print(a_tokens)\n",
        "a_seq_ids = bert_tokenizer.convert_tokens_to_ids(a_tokens)\n",
        "print(a_seq_ids)\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n",
        "batch_data = torch.Tensor(a_seq_ids).cuda().long().view((1,-1))\n",
        "out,_ = bert_model(batch_data)\n",
        "print(out[0].shape)\n",
        "print(out[0][0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3xf12_U9-NO"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertModel\n",
        "import torch\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "import numpy as np\n",
        "import csv\n",
        "label_List = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"FundRaising\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"ContextualInformation\",\n",
        "        \"News\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\",\n",
        "        \"OriginalEvent\"]\n",
        "important_list = [\"Low\",\n",
        "        \"Medium\",\n",
        "        \"High\",\n",
        "        \"Critical\"\n",
        "       ]\n",
        "tweets = []\n",
        "path = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention/data/ll.csv'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for line in reader:\n",
        "        tweet_full = line\n",
        "        tweets.append({\n",
        "            'id': tweet_full[0],\n",
        "            'label':tweet_full[1],\n",
        "            'important':tweet_full[2],\n",
        "            'text': tweet_full[3].lower(),\n",
        "            # 'name': tweet_full['user']['name'].split()[0]\n",
        "            })\n",
        "tweet_list = []\n",
        "text_list = []\n",
        "imformation_list = []\n",
        "important_list = []\n",
        "label_list = []\n",
        "q = 0\n",
        "for i in range(len(tweets)):\n",
        "        #text_list.append(tweets[i]['text'])\n",
        "        a_tokens = bert_tokenizer.tokenize(tweets[i]['text'])\n",
        "        a_seq_ids = bert_tokenizer.convert_tokens_to_ids(a_tokens)\n",
        "        batch_data = torch.Tensor(a_seq_ids).cuda().long().view((1,-1))\n",
        "        bert_model.eval()\n",
        "        out,_ = bert_model(batch_data)\n",
        "        #print(type(out[0][0]))\n",
        "        print(q)\n",
        "        if q == 3000:\n",
        "          break\n",
        "        tweets_vector = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        tweets_label = eval(tweets[i]['label'])\n",
        "        tweets_important = tweets[i]['important']\n",
        "        p = 0\n",
        "        for j in label_List:\n",
        "            for k in tweets_label:\n",
        "                if k == j:\n",
        "                    tweets_vector[p] = 1\n",
        "            p+=1\n",
        "        for q in important_List:\n",
        "            for l in tweets_label:\n",
        "                if l == q:\n",
        "                    tweets_vector[p] = 1\n",
        "            p+=1\n",
        "        label_list.append(tweets_vector)\n",
        "        text_list.append(out[0][0].cpu())\n",
        "        q+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bFdoPwYAAjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93ccec2-d0a3-4821-c184-8ad3b6bd6714"
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nGWoU96hUfO"
      },
      "source": [
        "a = np.array(label_list)\n",
        "b = np.array(text_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkmTEwHX__uq"
      },
      "source": [
        "np.save('./data/Bert_label1.npy',a)\n",
        "np.save('./data/Bert_text1.npy',b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rqyyXrTh2Uj"
      },
      "source": [
        "c = np.load('./data/Bert_text1.npy',allow_pickle=True)\n",
        "d = c.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}