{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whs1111/bert-version/blob/master/src/CLASS/Bert-6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb0U7ctSDcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "061bdd71-aee1-4c07-bc8f-f4b1abadfbd6"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orTnaAutSYb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c987b89-b2f6-411e-ab57-2ac5cfb3ce04"
      },
      "source": [
        "cd gdrive/My Drive/Colab_Notebooks/code\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Colab_Notebooks/code'\n",
            "/content/gdrive/My Drive/Colab_Notebooks/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq86DU7W7lO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLeNJNgJ9xId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fast-bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnAozJ8H7wpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fast_bert.data_cls import BertDataBunch\n",
        "DATA_PATH = 'bert-version/src/DATA/'   \n",
        "LABEL_PATH = 'bert-version/src/DATA/'  \n",
        "# label_cols = [\"Low\",\n",
        "#              \"Medium\",\n",
        "#              \"High\",\n",
        "#              \"Critical\"]\n",
        "label_cols = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"FundRaising\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"News\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"OriginalEvent\",\n",
        "        \"ContextualInformation\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\"]\n",
        "             \n",
        "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
        "                          tokenizer='bert-base-uncased',\n",
        "                          train_file='train.csv',\n",
        "                          val_file='valid.csv',\n",
        "                          label_file='labels.csv',\n",
        "                          text_col='text',\n",
        "                          label_col=label_cols,\n",
        "                          batch_size_per_gpu=1,\n",
        "                          max_seq_length=140,\n",
        "                          multi_gpu=False,\n",
        "                          multi_label=True,\n",
        "                          model_type='bert')\n",
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy\n",
        "import logging\n",
        "import torch\n",
        "logger = logging.getLogger()\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "metrics = [{'name': 'accuracy', 'function': accuracy}]\n",
        "\n",
        "learner = BertLearner.from_pretrained_model(\n",
        "\t\t\t\t\t\tdatabunch,\n",
        "\t\t\t\t\t\tpretrained_path='bert-base-uncased',\n",
        "\t\t\t\t\t\tmetrics=metrics,\n",
        "\t\t\t\t\t\tdevice=device_cuda,\n",
        "\t\t\t\t\t\tlogger=logger,\n",
        "\t\t\t\t\t\toutput_dir='bert-version/src/',\n",
        "\t\t\t\t\t\tfinetuned_wgts_path=None,\n",
        "\t\t\t\t\t\twarmup_steps=500,\n",
        "\t\t\t\t\t\tmulti_gpu=False,\n",
        "\t\t\t\t\t\tis_fp16=True,\n",
        "\t\t\t\t\t\tmulti_label=True,\n",
        "\t\t\t\t\t\tlogging_steps=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy3VFpqHEqmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUqTMEKN_ocQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "learner.fit(epochs=1,\n",
        "\t\t\tlr=6e-5,\n",
        "\t\t\tvalidate=True, \t# Evaluate the model after each epoch\n",
        "\t\t\tschedule_type=\"warmup_cosine\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQBkVk2Begvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save_model()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aDWvRice71G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from fast_bert.prediction import BertClassificationPredictor\n",
        "DATA_PATH = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/'   \n",
        "LABEL_PATH = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA'  \n",
        "MODEL_PATH = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/model_out'\n",
        "\n",
        "predictor = BertClassificationPredictor(\n",
        "\t\t\t\tmodel_path=MODEL_PATH,\n",
        "\t\t\t\tlabel_path=LABEL_PATH, # location for labels.csv file\n",
        "\t\t\t\tmulti_label=False,\n",
        "\t\t\t\tmodel_type='bert',\n",
        "\t\t\t\tdo_lower_case=True)\n",
        "\n",
        "file = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/test.csv'\n",
        "combi = pd.read_csv(file)\n",
        "lens = len(combi['text'])\n",
        "labels = []\n",
        "texts = []\n",
        "for i in range(lens):\n",
        "     label = []\n",
        "     i = 0\n",
        "     texts.append(combi['text'][i])\n",
        "multiple_predictions = predictor.predict_batch(texts)\n",
        "    #  single_prediction = predictor.predict(combi['text'][i])\n",
        "#      for j in range(len(single_prediction)):\n",
        "#        if single_prediction[j][1]>0.4:\n",
        "#          label.append(single_prediction[j])\n",
        "#          break\n",
        "#      labels.append(label)\n",
        "# numpy_array = np.array(labels)\n",
        "# np.save('category.npy',numpy_array )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNs9soyfIdAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd ..\n",
        "\n",
        "import torch\n",
        "import apex\n",
        "from fastai.text import *\n",
        "import datetime\n",
        "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "LOG_PATH=Path('logs/')  \n",
        "MODEL_PATH=Path('models/') \n",
        "\n",
        "if not LOG_PATH.exists():\n",
        "  LOG_PATH.mkdir()\n",
        "import logging\n",
        "\n",
        "args = {\n",
        "    \"run_text\": \"my_test\",\n",
        "    \"max_seq_length\": 30,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 16,\n",
        "    \"learning_rate\": 6e-5,\n",
        "    \"num_train_epochs\": 12.0,\n",
        "    \"warmup_proportion\": 0.002,\n",
        "    \"local_rank\": -1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"fp16\": True,\n",
        "    \"loss_scale\": 128\n",
        "}\n",
        "\n",
        "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(logfile),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ])\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    multi_gpu = True\n",
        "else:\n",
        "    multi_gpu = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4XFda_IIpeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fast-bert==0.1.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9MxKeV0IuqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fast_bert.data import *\n",
        "from fast_bert.learner import *\n",
        "from fast_bert.metrics import *\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLU0cuaYI3vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = Path('bert-version/src/DATA/')     \n",
        "LABEL_PATH = Path('bert-version/src/DATA/')  \n",
        "\n",
        "BERT_PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "\n",
        "args[\"do_lower_case\"] = True\n",
        "args[\"train_batch_size\"] = 16\n",
        "args[\"learning_rate\"] = 6e-5\n",
        "args[\"max_seq_length\"] = 140\n",
        "args[\"fp16\"] = True\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_MODEL, \n",
        "                                          do_lower_case=args['do_lower_case'])\n",
        "label_cols = [\"Low\",\n",
        "             \"Medium\",\n",
        "             \"High\",\n",
        "             \"Critical\"]\n",
        "databunch = BertDataBunch(DATA_PATH, LABEL_PATH, tokenizer, train_file='train.csv', val_file='valid.csv',\n",
        "                          test_data='test.csv', label_file=\"labels.csv\",\n",
        "                          text_col=\"text\", label_col=label_cols,\n",
        "                          bs=args['train_batch_size'], maxlen=args['max_seq_length'], \n",
        "                          multi_gpu=multi_gpu, multi_label=True)\n",
        "metrics = [{'name': 'accuracy', 'function': accuracy_multilabel}]\n",
        "logger.info(args)\n",
        "learner = BertLearner.from_pretrained_model(databunch, BERT_PRETRAINED_MODEL, metrics, device, logger, \n",
        "                                            is_fp16=args['fp16'], loss_scale=args['loss_scale'], \n",
        "                                            multi_gpu=multi_gpu,  multi_label=True)\n",
        "learner.fit(8, lr=args['learning_rate'], schedule_type=\"warmup_linear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsJC2lxsI6gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save_and_reload('/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/', \"bert-model\")\n",
        "from fast_bert.prediction import BertClassificationPredictor\n",
        "import numpy as np \n",
        "\n",
        "predictor = BertClassificationPredictor(model_path='bert-version/src/DATA/bert-model.bin', pretrained_path=\"bert-base-uncased\", \n",
        "                                        label_path='/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/', multi_label=True)\n",
        "\n",
        "# texts = []\n",
        "file = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/DATA/test.csv'\n",
        "combi = pd.read_csv(file)\n",
        "lens = len(combi['text'])\n",
        "labels = []\n",
        "for i in range(lens):\n",
        "#     texts.append(combi['text'][i])\n",
        "    label = []\n",
        "    single_prediction = predictor.predict(combi['text'][i])\n",
        "    for j in range(len(single_prediction)):\n",
        "      if single_prediction[j][1]>0.3:\n",
        "        label.append(single_prediction[0])\n",
        "    labels.append(label)\n",
        "numpy_array = np.array(labels)\n",
        "np.save('category.npy',numpy_array )\n",
        "label_cols = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"FundRaising\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"ContextualInformation\",\n",
        "        \"News\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\",\n",
        "        \"OriginalEvent\"]\n",
        "        \n",
        "# print(single_prediction)\n",
        "\n",
        "# Batch predictions\n",
        "# texts = [\n",
        "#   \"this is the first text\",\n",
        "#   \"this is the second text\"\n",
        "# ]\n",
        "\n",
        "# multiple_predictions = predictor.predict(texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}