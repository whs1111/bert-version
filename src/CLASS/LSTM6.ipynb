{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whs1111/bert-version/blob/master/src/CLASS/LSTM6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMb0U7ctSDcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ee00ef-36bd-499b-c0c5-8565cd39c702"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS8U2HuDtZix"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orTnaAutSYb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373ab4db-4ff1-436e-eb5f-5ae2876dcfa5"
      },
      "source": [
        "cd gdrive/My Drive/Colab_Notebooks/code\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNs9soyfIdAY"
      },
      "source": [
        "#@title\n",
        "!git clone https://github.com/NVIDIA/apex.git\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "%cd ..\n",
        "\n",
        "import torch\n",
        "import apex\n",
        "from fastai.text import *\n",
        "import datetime\n",
        "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "LOG_PATH=Path('logs/')  \n",
        "MODEL_PATH=Path('models/') \n",
        "\n",
        "if not LOG_PATH.exists():\n",
        "  LOG_PATH.mkdir()\n",
        "import logging\n",
        "\n",
        "args = {\n",
        "    \"run_text\": \"my_test\",\n",
        "    \"max_seq_length\": 30,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 16,\n",
        "    \"learning_rate\": 6e-5,\n",
        "    \"num_train_epochs\": 12.0,\n",
        "    \"warmup_proportion\": 0.002,\n",
        "    \"local_rank\": -1,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"fp16\": True,\n",
        "    \"loss_scale\": 128\n",
        "}\n",
        "\n",
        "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler(logfile),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ])\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    multi_gpu = True\n",
        "else:\n",
        "    multi_gpu = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdR4a-QwQIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cd8801-d204-4e76-8085-b3e605e3a1f8"
      },
      "source": [
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/c2/c506760afd5ed0576baf297a36cab161ffaa7535dfbaae8f88bfd6aa1b94/boto3-1.16.47.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.19.4)\n",
            "Collecting botocore<1.20.0,>=1.19.47\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/4a/16ffdfc33d93f02604ae9ed1ddb6369030b6f61b583f31dc84e0d0da05c1/botocore-1.19.47-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 12.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.47->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.47->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Building wheels for collected packages: boto3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.16.47-py2.py3-none-any.whl size=128711 sha256=b1a05e2ece73365c052e7b72ddac01b70f25c031a0b7ff59ad77e415849faa8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/81/49/643c45ae820b8df3dfd4b8218f4990fc6ca8eac47b281bd675\n",
            "Successfully built boto3\n",
            "\u001b[31mERROR: botocore 1.19.47 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.47 botocore-1.19.47 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UPCpIKpC7Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43680a10-1fd3-4661-a964-00be1de3957d"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxTo7cgvvy_C"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertModel\n",
        "import torch\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "a = \"i am a dog\"\n",
        "a_tokens = bert_tokenizer.tokenize(a)\n",
        "print(a_tokens)\n",
        "a_seq_ids = bert_tokenizer.convert_tokens_to_ids(a_tokens)\n",
        "print(a_seq_ids)\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n",
        "batch_data = torch.Tensor(a_seq_ids).cuda().long().view((1,-1))\n",
        "out,_ = bert_model(batch_data)\n",
        "print(out[0].shape)\n",
        "print(out[0][0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3xf12_U9-NO",
        "outputId": "98b0562a-d2da-4143-88b8-ff03a7406939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertModel\n",
        "import torch\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(\"cuda\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "import numpy as np\n",
        "import csv\n",
        "label_List = [\"GoodsServices\",\n",
        "        \"SearchAndRescue\",\n",
        "        \"InformationWanted\",\n",
        "        \"Volunteer\",\n",
        "        \"FundRaising\",\n",
        "        \"Donations\",\n",
        "        \"MovePeople\",\n",
        "        \"FirstPartyObservation\",\n",
        "        \"ThirdPartyObservation\",\n",
        "        \"Weather\",\n",
        "        \"EmergingThreats\",\n",
        "        \"NewSubEvent\",\n",
        "        \"MultimediaShare\",\n",
        "        \"ServiceAvailable\",\n",
        "        \"Factoid\",\n",
        "        \"Official\",\n",
        "        \"CleanUp\",\n",
        "        \"Hashtags\",\n",
        "        \"ContextualInformation\",\n",
        "        \"News\",\n",
        "        \"Advice\",\n",
        "        \"Sentiment\",\n",
        "        \"Discussion\",\n",
        "        \"Irrelevant\",\n",
        "        \"OriginalEvent\"]\n",
        "important_list = [\"Low\",\n",
        "        \"Medium\",\n",
        "        \"High\",\n",
        "        \"Critical\"\n",
        "       ]\n",
        "tweets = []\n",
        "path = '/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention/data/ll.csv'\n",
        "with open(path, 'r', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for line in reader:\n",
        "        tweet_full = line\n",
        "        tweets.append({\n",
        "            'id': tweet_full[0],\n",
        "            'label':tweet_full[1],\n",
        "            'important':tweet_full[2],\n",
        "            'text': tweet_full[3].lower(),\n",
        "            # 'name': tweet_full['user']['name'].split()[0]\n",
        "            })\n",
        "tweet_list = []\n",
        "text_list = []\n",
        "imformation_list = []\n",
        "important_list = []\n",
        "label_list = []\n",
        "text_list = []\n",
        "label_list = []\n",
        "# text_list = np.load('./data/Bert_text1.npy',allow_pickle=True).tolist()\n",
        "# label_list = np.load('./data/Bert_label1.npy',allow_pickle=True).tolist()\n",
        "for i in range(len(tweets)):\n",
        "        if ( i == 3000):\n",
        "          break\n",
        "        # if(i < 3000):\n",
        "        #   continue\n",
        "        # if(i== 6000):\n",
        "        #   break\n",
        "        #text_list.append(tweets[i]['text'])\n",
        "        a_tokens = bert_tokenizer.tokenize(tweets[i]['text'])\n",
        "        print(i)\n",
        "        a_seq_ids = bert_tokenizer.convert_tokens_to_ids(a_tokens)\n",
        "        batch_data = torch.Tensor(a_seq_ids).cuda().long().view((1,-1))\n",
        "        bert_model.eval()\n",
        "        out,_ = bert_model(batch_data)\n",
        "        #print(type(out[0][0]))\n",
        "        tweets_vector = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        tweets_label = eval(tweets[i]['label'])\n",
        "        tweets_important = tweets[i]['important']\n",
        "        p = 0\n",
        "        for j in label_List:\n",
        "            for k in tweets_label:\n",
        "                if k == j:\n",
        "                    tweets_vector[p] = 1\n",
        "            p+=1\n",
        "        for q in important_list:\n",
        "            for l in tweets_important:\n",
        "                if l == q:\n",
        "                    tweets_vector[p] = 1\n",
        "            p+=1\n",
        "        label_list.append(tweets_vector)\n",
        "        text_list.append(out[0][0].cpu())\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "3001\n",
            "3002\n",
            "3003\n",
            "3004\n",
            "3005\n",
            "3006\n",
            "3007\n",
            "3008\n",
            "3009\n",
            "3010\n",
            "3011\n",
            "3012\n",
            "3013\n",
            "3014\n",
            "3015\n",
            "3016\n",
            "3017\n",
            "3018\n",
            "3019\n",
            "3020\n",
            "3021\n",
            "3022\n",
            "3023\n",
            "3024\n",
            "3025\n",
            "3026\n",
            "3027\n",
            "3028\n",
            "3029\n",
            "3030\n",
            "3031\n",
            "3032\n",
            "3033\n",
            "3034\n",
            "3035\n",
            "3036\n",
            "3037\n",
            "3038\n",
            "3039\n",
            "3040\n",
            "3041\n",
            "3042\n",
            "3043\n",
            "3044\n",
            "3045\n",
            "3046\n",
            "3047\n",
            "3048\n",
            "3049\n",
            "3050\n",
            "3051\n",
            "3052\n",
            "3053\n",
            "3054\n",
            "3055\n",
            "3056\n",
            "3057\n",
            "3058\n",
            "3059\n",
            "3060\n",
            "3061\n",
            "3062\n",
            "3063\n",
            "3064\n",
            "3065\n",
            "3066\n",
            "3067\n",
            "3068\n",
            "3069\n",
            "3070\n",
            "3071\n",
            "3072\n",
            "3073\n",
            "3074\n",
            "3075\n",
            "3076\n",
            "3077\n",
            "3078\n",
            "3079\n",
            "3080\n",
            "3081\n",
            "3082\n",
            "3083\n",
            "3084\n",
            "3085\n",
            "3086\n",
            "3087\n",
            "3088\n",
            "3089\n",
            "3090\n",
            "3091\n",
            "3092\n",
            "3093\n",
            "3094\n",
            "3095\n",
            "3096\n",
            "3097\n",
            "3098\n",
            "3099\n",
            "3100\n",
            "3101\n",
            "3102\n",
            "3103\n",
            "3104\n",
            "3105\n",
            "3106\n",
            "3107\n",
            "3108\n",
            "3109\n",
            "3110\n",
            "3111\n",
            "3112\n",
            "3113\n",
            "3114\n",
            "3115\n",
            "3116\n",
            "3117\n",
            "3118\n",
            "3119\n",
            "3120\n",
            "3121\n",
            "3122\n",
            "3123\n",
            "3124\n",
            "3125\n",
            "3126\n",
            "3127\n",
            "3128\n",
            "3129\n",
            "3130\n",
            "3131\n",
            "3132\n",
            "3133\n",
            "3134\n",
            "3135\n",
            "3136\n",
            "3137\n",
            "3138\n",
            "3139\n",
            "3140\n",
            "3141\n",
            "3142\n",
            "3143\n",
            "3144\n",
            "3145\n",
            "3146\n",
            "3147\n",
            "3148\n",
            "3149\n",
            "3150\n",
            "3151\n",
            "3152\n",
            "3153\n",
            "3154\n",
            "3155\n",
            "3156\n",
            "3157\n",
            "3158\n",
            "3159\n",
            "3160\n",
            "3161\n",
            "3162\n",
            "3163\n",
            "3164\n",
            "3165\n",
            "3166\n",
            "3167\n",
            "3168\n",
            "3169\n",
            "3170\n",
            "3171\n",
            "3172\n",
            "3173\n",
            "3174\n",
            "3175\n",
            "3176\n",
            "3177\n",
            "3178\n",
            "3179\n",
            "3180\n",
            "3181\n",
            "3182\n",
            "3183\n",
            "3184\n",
            "3185\n",
            "3186\n",
            "3187\n",
            "3188\n",
            "3189\n",
            "3190\n",
            "3191\n",
            "3192\n",
            "3193\n",
            "3194\n",
            "3195\n",
            "3196\n",
            "3197\n",
            "3198\n",
            "3199\n",
            "3200\n",
            "3201\n",
            "3202\n",
            "3203\n",
            "3204\n",
            "3205\n",
            "3206\n",
            "3207\n",
            "3208\n",
            "3209\n",
            "3210\n",
            "3211\n",
            "3212\n",
            "3213\n",
            "3214\n",
            "3215\n",
            "3216\n",
            "3217\n",
            "3218\n",
            "3219\n",
            "3220\n",
            "3221\n",
            "3222\n",
            "3223\n",
            "3224\n",
            "3225\n",
            "3226\n",
            "3227\n",
            "3228\n",
            "3229\n",
            "3230\n",
            "3231\n",
            "3232\n",
            "3233\n",
            "3234\n",
            "3235\n",
            "3236\n",
            "3237\n",
            "3238\n",
            "3239\n",
            "3240\n",
            "3241\n",
            "3242\n",
            "3243\n",
            "3244\n",
            "3245\n",
            "3246\n",
            "3247\n",
            "3248\n",
            "3249\n",
            "3250\n",
            "3251\n",
            "3252\n",
            "3253\n",
            "3254\n",
            "3255\n",
            "3256\n",
            "3257\n",
            "3258\n",
            "3259\n",
            "3260\n",
            "3261\n",
            "3262\n",
            "3263\n",
            "3264\n",
            "3265\n",
            "3266\n",
            "3267\n",
            "3268\n",
            "3269\n",
            "3270\n",
            "3271\n",
            "3272\n",
            "3273\n",
            "3274\n",
            "3275\n",
            "3276\n",
            "3277\n",
            "3278\n",
            "3279\n",
            "3280\n",
            "3281\n",
            "3282\n",
            "3283\n",
            "3284\n",
            "3285\n",
            "3286\n",
            "3287\n",
            "3288\n",
            "3289\n",
            "3290\n",
            "3291\n",
            "3292\n",
            "3293\n",
            "3294\n",
            "3295\n",
            "3296\n",
            "3297\n",
            "3298\n",
            "3299\n",
            "3300\n",
            "3301\n",
            "3302\n",
            "3303\n",
            "3304\n",
            "3305\n",
            "3306\n",
            "3307\n",
            "3308\n",
            "3309\n",
            "3310\n",
            "3311\n",
            "3312\n",
            "3313\n",
            "3314\n",
            "3315\n",
            "3316\n",
            "3317\n",
            "3318\n",
            "3319\n",
            "3320\n",
            "3321\n",
            "3322\n",
            "3323\n",
            "3324\n",
            "3325\n",
            "3326\n",
            "3327\n",
            "3328\n",
            "3329\n",
            "3330\n",
            "3331\n",
            "3332\n",
            "3333\n",
            "3334\n",
            "3335\n",
            "3336\n",
            "3337\n",
            "3338\n",
            "3339\n",
            "3340\n",
            "3341\n",
            "3342\n",
            "3343\n",
            "3344\n",
            "3345\n",
            "3346\n",
            "3347\n",
            "3348\n",
            "3349\n",
            "3350\n",
            "3351\n",
            "3352\n",
            "3353\n",
            "3354\n",
            "3355\n",
            "3356\n",
            "3357\n",
            "3358\n",
            "3359\n",
            "3360\n",
            "3361\n",
            "3362\n",
            "3363\n",
            "3364\n",
            "3365\n",
            "3366\n",
            "3367\n",
            "3368\n",
            "3369\n",
            "3370\n",
            "3371\n",
            "3372\n",
            "3373\n",
            "3374\n",
            "3375\n",
            "3376\n",
            "3377\n",
            "3378\n",
            "3379\n",
            "3380\n",
            "3381\n",
            "3382\n",
            "3383\n",
            "3384\n",
            "3385\n",
            "3386\n",
            "3387\n",
            "3388\n",
            "3389\n",
            "3390\n",
            "3391\n",
            "3392\n",
            "3393\n",
            "3394\n",
            "3395\n",
            "3396\n",
            "3397\n",
            "3398\n",
            "3399\n",
            "3400\n",
            "3401\n",
            "3402\n",
            "3403\n",
            "3404\n",
            "3405\n",
            "3406\n",
            "3407\n",
            "3408\n",
            "3409\n",
            "3410\n",
            "3411\n",
            "3412\n",
            "3413\n",
            "3414\n",
            "3415\n",
            "3416\n",
            "3417\n",
            "3418\n",
            "3419\n",
            "3420\n",
            "3421\n",
            "3422\n",
            "3423\n",
            "3424\n",
            "3425\n",
            "3426\n",
            "3427\n",
            "3428\n",
            "3429\n",
            "3430\n",
            "3431\n",
            "3432\n",
            "3433\n",
            "3434\n",
            "3435\n",
            "3436\n",
            "3437\n",
            "3438\n",
            "3439\n",
            "3440\n",
            "3441\n",
            "3442\n",
            "3443\n",
            "3444\n",
            "3445\n",
            "3446\n",
            "3447\n",
            "3448\n",
            "3449\n",
            "3450\n",
            "3451\n",
            "3452\n",
            "3453\n",
            "3454\n",
            "3455\n",
            "3456\n",
            "3457\n",
            "3458\n",
            "3459\n",
            "3460\n",
            "3461\n",
            "3462\n",
            "3463\n",
            "3464\n",
            "3465\n",
            "3466\n",
            "3467\n",
            "3468\n",
            "3469\n",
            "3470\n",
            "3471\n",
            "3472\n",
            "3473\n",
            "3474\n",
            "3475\n",
            "3476\n",
            "3477\n",
            "3478\n",
            "3479\n",
            "3480\n",
            "3481\n",
            "3482\n",
            "3483\n",
            "3484\n",
            "3485\n",
            "3486\n",
            "3487\n",
            "3488\n",
            "3489\n",
            "3490\n",
            "3491\n",
            "3492\n",
            "3493\n",
            "3494\n",
            "3495\n",
            "3496\n",
            "3497\n",
            "3498\n",
            "3499\n",
            "3500\n",
            "3501\n",
            "3502\n",
            "3503\n",
            "3504\n",
            "3505\n",
            "3506\n",
            "3507\n",
            "3508\n",
            "3509\n",
            "3510\n",
            "3511\n",
            "3512\n",
            "3513\n",
            "3514\n",
            "3515\n",
            "3516\n",
            "3517\n",
            "3518\n",
            "3519\n",
            "3520\n",
            "3521\n",
            "3522\n",
            "3523\n",
            "3524\n",
            "3525\n",
            "3526\n",
            "3527\n",
            "3528\n",
            "3529\n",
            "3530\n",
            "3531\n",
            "3532\n",
            "3533\n",
            "3534\n",
            "3535\n",
            "3536\n",
            "3537\n",
            "3538\n",
            "3539\n",
            "3540\n",
            "3541\n",
            "3542\n",
            "3543\n",
            "3544\n",
            "3545\n",
            "3546\n",
            "3547\n",
            "3548\n",
            "3549\n",
            "3550\n",
            "3551\n",
            "3552\n",
            "3553\n",
            "3554\n",
            "3555\n",
            "3556\n",
            "3557\n",
            "3558\n",
            "3559\n",
            "3560\n",
            "3561\n",
            "3562\n",
            "3563\n",
            "3564\n",
            "3565\n",
            "3566\n",
            "3567\n",
            "3568\n",
            "3569\n",
            "3570\n",
            "3571\n",
            "3572\n",
            "3573\n",
            "3574\n",
            "3575\n",
            "3576\n",
            "3577\n",
            "3578\n",
            "3579\n",
            "3580\n",
            "3581\n",
            "3582\n",
            "3583\n",
            "3584\n",
            "3585\n",
            "3586\n",
            "3587\n",
            "3588\n",
            "3589\n",
            "3590\n",
            "3591\n",
            "3592\n",
            "3593\n",
            "3594\n",
            "3595\n",
            "3596\n",
            "3597\n",
            "3598\n",
            "3599\n",
            "3600\n",
            "3601\n",
            "3602\n",
            "3603\n",
            "3604\n",
            "3605\n",
            "3606\n",
            "3607\n",
            "3608\n",
            "3609\n",
            "3610\n",
            "3611\n",
            "3612\n",
            "3613\n",
            "3614\n",
            "3615\n",
            "3616\n",
            "3617\n",
            "3618\n",
            "3619\n",
            "3620\n",
            "3621\n",
            "3622\n",
            "3623\n",
            "3624\n",
            "3625\n",
            "3626\n",
            "3627\n",
            "3628\n",
            "3629\n",
            "3630\n",
            "3631\n",
            "3632\n",
            "3633\n",
            "3634\n",
            "3635\n",
            "3636\n",
            "3637\n",
            "3638\n",
            "3639\n",
            "3640\n",
            "3641\n",
            "3642\n",
            "3643\n",
            "3644\n",
            "3645\n",
            "3646\n",
            "3647\n",
            "3648\n",
            "3649\n",
            "3650\n",
            "3651\n",
            "3652\n",
            "3653\n",
            "3654\n",
            "3655\n",
            "3656\n",
            "3657\n",
            "3658\n",
            "3659\n",
            "3660\n",
            "3661\n",
            "3662\n",
            "3663\n",
            "3664\n",
            "3665\n",
            "3666\n",
            "3667\n",
            "3668\n",
            "3669\n",
            "3670\n",
            "3671\n",
            "3672\n",
            "3673\n",
            "3674\n",
            "3675\n",
            "3676\n",
            "3677\n",
            "3678\n",
            "3679\n",
            "3680\n",
            "3681\n",
            "3682\n",
            "3683\n",
            "3684\n",
            "3685\n",
            "3686\n",
            "3687\n",
            "3688\n",
            "3689\n",
            "3690\n",
            "3691\n",
            "3692\n",
            "3693\n",
            "3694\n",
            "3695\n",
            "3696\n",
            "3697\n",
            "3698\n",
            "3699\n",
            "3700\n",
            "3701\n",
            "3702\n",
            "3703\n",
            "3704\n",
            "3705\n",
            "3706\n",
            "3707\n",
            "3708\n",
            "3709\n",
            "3710\n",
            "3711\n",
            "3712\n",
            "3713\n",
            "3714\n",
            "3715\n",
            "3716\n",
            "3717\n",
            "3718\n",
            "3719\n",
            "3720\n",
            "3721\n",
            "3722\n",
            "3723\n",
            "3724\n",
            "3725\n",
            "3726\n",
            "3727\n",
            "3728\n",
            "3729\n",
            "3730\n",
            "3731\n",
            "3732\n",
            "3733\n",
            "3734\n",
            "3735\n",
            "3736\n",
            "3737\n",
            "3738\n",
            "3739\n",
            "3740\n",
            "3741\n",
            "3742\n",
            "3743\n",
            "3744\n",
            "3745\n",
            "3746\n",
            "3747\n",
            "3748\n",
            "3749\n",
            "3750\n",
            "3751\n",
            "3752\n",
            "3753\n",
            "3754\n",
            "3755\n",
            "3756\n",
            "3757\n",
            "3758\n",
            "3759\n",
            "3760\n",
            "3761\n",
            "3762\n",
            "3763\n",
            "3764\n",
            "3765\n",
            "3766\n",
            "3767\n",
            "3768\n",
            "3769\n",
            "3770\n",
            "3771\n",
            "3772\n",
            "3773\n",
            "3774\n",
            "3775\n",
            "3776\n",
            "3777\n",
            "3778\n",
            "3779\n",
            "3780\n",
            "3781\n",
            "3782\n",
            "3783\n",
            "3784\n",
            "3785\n",
            "3786\n",
            "3787\n",
            "3788\n",
            "3789\n",
            "3790\n",
            "3791\n",
            "3792\n",
            "3793\n",
            "3794\n",
            "3795\n",
            "3796\n",
            "3797\n",
            "3798\n",
            "3799\n",
            "3800\n",
            "3801\n",
            "3802\n",
            "3803\n",
            "3804\n",
            "3805\n",
            "3806\n",
            "3807\n",
            "3808\n",
            "3809\n",
            "3810\n",
            "3811\n",
            "3812\n",
            "3813\n",
            "3814\n",
            "3815\n",
            "3816\n",
            "3817\n",
            "3818\n",
            "3819\n",
            "3820\n",
            "3821\n",
            "3822\n",
            "3823\n",
            "3824\n",
            "3825\n",
            "3826\n",
            "3827\n",
            "3828\n",
            "3829\n",
            "3830\n",
            "3831\n",
            "3832\n",
            "3833\n",
            "3834\n",
            "3835\n",
            "3836\n",
            "3837\n",
            "3838\n",
            "3839\n",
            "3840\n",
            "3841\n",
            "3842\n",
            "3843\n",
            "3844\n",
            "3845\n",
            "3846\n",
            "3847\n",
            "3848\n",
            "3849\n",
            "3850\n",
            "3851\n",
            "3852\n",
            "3853\n",
            "3854\n",
            "3855\n",
            "3856\n",
            "3857\n",
            "3858\n",
            "3859\n",
            "3860\n",
            "3861\n",
            "3862\n",
            "3863\n",
            "3864\n",
            "3865\n",
            "3866\n",
            "3867\n",
            "3868\n",
            "3869\n",
            "3870\n",
            "3871\n",
            "3872\n",
            "3873\n",
            "3874\n",
            "3875\n",
            "3876\n",
            "3877\n",
            "3878\n",
            "3879\n",
            "3880\n",
            "3881\n",
            "3882\n",
            "3883\n",
            "3884\n",
            "3885\n",
            "3886\n",
            "3887\n",
            "3888\n",
            "3889\n",
            "3890\n",
            "3891\n",
            "3892\n",
            "3893\n",
            "3894\n",
            "3895\n",
            "3896\n",
            "3897\n",
            "3898\n",
            "3899\n",
            "3900\n",
            "3901\n",
            "3902\n",
            "3903\n",
            "3904\n",
            "3905\n",
            "3906\n",
            "3907\n",
            "3908\n",
            "3909\n",
            "3910\n",
            "3911\n",
            "3912\n",
            "3913\n",
            "3914\n",
            "3915\n",
            "3916\n",
            "3917\n",
            "3918\n",
            "3919\n",
            "3920\n",
            "3921\n",
            "3922\n",
            "3923\n",
            "3924\n",
            "3925\n",
            "3926\n",
            "3927\n",
            "3928\n",
            "3929\n",
            "3930\n",
            "3931\n",
            "3932\n",
            "3933\n",
            "3934\n",
            "3935\n",
            "3936\n",
            "3937\n",
            "3938\n",
            "3939\n",
            "3940\n",
            "3941\n",
            "3942\n",
            "3943\n",
            "3944\n",
            "3945\n",
            "3946\n",
            "3947\n",
            "3948\n",
            "3949\n",
            "3950\n",
            "3951\n",
            "3952\n",
            "3953\n",
            "3954\n",
            "3955\n",
            "3956\n",
            "3957\n",
            "3958\n",
            "3959\n",
            "3960\n",
            "3961\n",
            "3962\n",
            "3963\n",
            "3964\n",
            "3965\n",
            "3966\n",
            "3967\n",
            "3968\n",
            "3969\n",
            "3970\n",
            "3971\n",
            "3972\n",
            "3973\n",
            "3974\n",
            "3975\n",
            "3976\n",
            "3977\n",
            "3978\n",
            "3979\n",
            "3980\n",
            "3981\n",
            "3982\n",
            "3983\n",
            "3984\n",
            "3985\n",
            "3986\n",
            "3987\n",
            "3988\n",
            "3989\n",
            "3990\n",
            "3991\n",
            "3992\n",
            "3993\n",
            "3994\n",
            "3995\n",
            "3996\n",
            "3997\n",
            "3998\n",
            "3999\n",
            "4000\n",
            "4001\n",
            "4002\n",
            "4003\n",
            "4004\n",
            "4005\n",
            "4006\n",
            "4007\n",
            "4008\n",
            "4009\n",
            "4010\n",
            "4011\n",
            "4012\n",
            "4013\n",
            "4014\n",
            "4015\n",
            "4016\n",
            "4017\n",
            "4018\n",
            "4019\n",
            "4020\n",
            "4021\n",
            "4022\n",
            "4023\n",
            "4024\n",
            "4025\n",
            "4026\n",
            "4027\n",
            "4028\n",
            "4029\n",
            "4030\n",
            "4031\n",
            "4032\n",
            "4033\n",
            "4034\n",
            "4035\n",
            "4036\n",
            "4037\n",
            "4038\n",
            "4039\n",
            "4040\n",
            "4041\n",
            "4042\n",
            "4043\n",
            "4044\n",
            "4045\n",
            "4046\n",
            "4047\n",
            "4048\n",
            "4049\n",
            "4050\n",
            "4051\n",
            "4052\n",
            "4053\n",
            "4054\n",
            "4055\n",
            "4056\n",
            "4057\n",
            "4058\n",
            "4059\n",
            "4060\n",
            "4061\n",
            "4062\n",
            "4063\n",
            "4064\n",
            "4065\n",
            "4066\n",
            "4067\n",
            "4068\n",
            "4069\n",
            "4070\n",
            "4071\n",
            "4072\n",
            "4073\n",
            "4074\n",
            "4075\n",
            "4076\n",
            "4077\n",
            "4078\n",
            "4079\n",
            "4080\n",
            "4081\n",
            "4082\n",
            "4083\n",
            "4084\n",
            "4085\n",
            "4086\n",
            "4087\n",
            "4088\n",
            "4089\n",
            "4090\n",
            "4091\n",
            "4092\n",
            "4093\n",
            "4094\n",
            "4095\n",
            "4096\n",
            "4097\n",
            "4098\n",
            "4099\n",
            "4100\n",
            "4101\n",
            "4102\n",
            "4103\n",
            "4104\n",
            "4105\n",
            "4106\n",
            "4107\n",
            "4108\n",
            "4109\n",
            "4110\n",
            "4111\n",
            "4112\n",
            "4113\n",
            "4114\n",
            "4115\n",
            "4116\n",
            "4117\n",
            "4118\n",
            "4119\n",
            "4120\n",
            "4121\n",
            "4122\n",
            "4123\n",
            "4124\n",
            "4125\n",
            "4126\n",
            "4127\n",
            "4128\n",
            "4129\n",
            "4130\n",
            "4131\n",
            "4132\n",
            "4133\n",
            "4134\n",
            "4135\n",
            "4136\n",
            "4137\n",
            "4138\n",
            "4139\n",
            "4140\n",
            "4141\n",
            "4142\n",
            "4143\n",
            "4144\n",
            "4145\n",
            "4146\n",
            "4147\n",
            "4148\n",
            "4149\n",
            "4150\n",
            "4151\n",
            "4152\n",
            "4153\n",
            "4154\n",
            "4155\n",
            "4156\n",
            "4157\n",
            "4158\n",
            "4159\n",
            "4160\n",
            "4161\n",
            "4162\n",
            "4163\n",
            "4164\n",
            "4165\n",
            "4166\n",
            "4167\n",
            "4168\n",
            "4169\n",
            "4170\n",
            "4171\n",
            "4172\n",
            "4173\n",
            "4174\n",
            "4175\n",
            "4176\n",
            "4177\n",
            "4178\n",
            "4179\n",
            "4180\n",
            "4181\n",
            "4182\n",
            "4183\n",
            "4184\n",
            "4185\n",
            "4186\n",
            "4187\n",
            "4188\n",
            "4189\n",
            "4190\n",
            "4191\n",
            "4192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c6d9b4e1f0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_seq_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;31m#print(type(out[0][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtweets_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.73 GiB total capacity; 13.42 GiB already allocated; 3.88 MiB free; 13.79 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bFdoPwYAAjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78ee2de-e574-40b5-ed25-464985686c96"
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab_Notebooks/code/bert-version/src/attention\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nGWoU96hUfO",
        "outputId": "746e9415-a975-409b-c9b9-6f696e9a9b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = np.array(label_list)\n",
        "b = np.array(text_list)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkmTEwHX__uq"
      },
      "source": [
        "np.save('./data/Bert_label1.npy',a)\n",
        "np.save('./data/Bert_text1.npy',b)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rqyyXrTh2Uj",
        "outputId": "f4e85f54-ea42-4b45-b0c7-752082f87609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "c = np.load('./data/Bert_label36.npy',allow_pickle=True)\n",
        "\n",
        "print(c[3599])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}